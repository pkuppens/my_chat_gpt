{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_LangChain/DSpy Setup with Local Ollama Container Instance\n",
    "\n",
    "This notebook demonstrates how to set up LangChain and DSpy to work with a local Ollama container instance. We will cover the installation of necessary packages, configuration, and connection to the local Ollama instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install LangChain, DSpy, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langchain langchain_community langchain_ollama dspy requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Packages\n",
    "\n",
    "Next, we will import the necessary packages for our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy import ChainOfThought\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Connection to Local Ollama Instance\n",
    "\n",
    "We need to configure the connection to our local Ollama container instance. The following code sets up the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7dd6b",
   "metadata": {},
   "source": [
    "### Step 3.1: Setup Ollama Docker Container Instance\n",
    "\n",
    "*_Run the following step first. This step is only needed if the following step fails._*\n",
    "\n",
    "#### Ollama\n",
    "Ollama is a containerized environment for running and managing LLMs. It provides an API for interacting with the models.\n",
    "\n",
    "#### Setup Instructions\n",
    "1. Ensure Docker is installed and running on your machine.\n",
    "2. Check if there is a Docker container instance 'ollama' that can be (re-)started.\n",
    "3. _If no 'ollama' container exists_: Create and run a new Ollama container instance using the following command:\n",
    "   ```\n",
    "   docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n",
    "   ```\n",
    "4. Verify the Ollama instance is running by accessing [http://localhost:11434/api/version](http://localhost:11434/api/version).\n",
    "5. Verify programmatic connection by (re-)running the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API_URL = \"http://localhost:11434/api\"\n",
    "\n",
    "\n",
    "def get_ollama_version():\n",
    "    response = requests.get(f\"{OLLAMA_API_URL}/version\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "try:\n",
    "    ollama_version = get_ollama_version()\n",
    "    if ollama_version:\n",
    "        print(f\"Connected to Ollama version: {ollama_version}\")\n",
    "    else:\n",
    "        print(\"Failed to connect to Ollama instance.\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Failed to connect to Ollama instance, is the Docker container running?\")\n",
    "    input(\"Press Enter to continue...\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Minimal Documentation and Instructions\n",
    "\n",
    "### LangChain\n",
    "LangChain is a framework for building applications with large language models (LLMs). It provides tools and abstractions to simplify the development process.\n",
    "\n",
    "### DSpy\n",
    "DSpy is a data science library that offers various utilities for data manipulation, analysis, and visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate LangChain and DSpy Integration\n",
    "\n",
    "In this step, we will demonstrate how to use LangChain and DSpy together in a practical example. We will use LangChain to generate text and DSpy to analyze the generated text.\n",
    "\n",
    "### Example: Text Generation and Analysis\n",
    "\n",
    "1. Use LangChain to generate text based on a prompt.\n",
    "2. Use DSpy to analyze the generated text.\n",
    "\n",
    "#### Generate Text with LangChain\n",
    "We will use LangChain to generate text based on a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7eb3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str, nr_articles=3) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url=\"http://20.102.90.50:2017/wiki17_abstracts\")(query, k=nr_articles)\n",
    "    return [x[\"text\"] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a025f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With new dspy version 2.5:\n",
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\"ollama_chat/llama3.2\", api_base=\"http://localhost:11434\", api_key=\"\")\n",
    "rm = dspy.ColBERTv2(url=\"http://20.102.90.50:2017/wiki17_abstracts\")  # retrieval model\n",
    "dspy.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f800f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(\"Come up with 10 names for a song about infamous soccer players\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47797fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_role = rm(\"Chief Executive Officer\", k=1)[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ceo_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/)\n",
    "- [DSpy Documentation](https://dspy.ai/tutorials/rag/)\n",
    "- [LangChain and DSpy Integration](https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: BasicQA DSpy Example with Signature Class\n",
    "\n",
    "In this step, we will demonstrate a zero-shot example using DSpy and dspy.Signature class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e06321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the signature for the QA task\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "\n",
    "# Initialize the Predict module with the signature\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Provide a question to the model\n",
    "response = generate_answer(question=\"What is the capital of France?\")\n",
    "\n",
    "# Output the answer\n",
    "print(f\"Question: What is the capital of France?\")\n",
    "print(f\"Answer: {response.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: User Input for Software Project Idea\n",
    "\n",
    "In this step, we will prompt the user to write a software project idea, send it to the LLM, and display the feedback, summary, and plan.\n",
    "\n",
    "### Example: User Input and Feedback Loop\n",
    "\n",
    "1. Prompt the user to write a software project idea.\n",
    "2. Send the idea to the LLM and display the feedback, summary, and plan.\n",
    "3. Implement a refinement loop to allow the user to provide additional input and receive updated feedback.\n",
    "\n",
    "#### Prompt User for Software Project Idea\n",
    "We will prompt the user to write a software project idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Get user input for software project idea, default to\n",
    "project_idea = (\n",
    "    input(\"Please write your software project idea: \")\n",
    "    or \"Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\"\n",
    ")\n",
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44bca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom chain that uses a single-step prompt\n",
    "# but instructs the model to produce the summary, strengths, and improvement_areas in one go.\n",
    "initial_feedback = ChainOfThought(\"idea -> feedback\")\n",
    "\n",
    "# Call the chain\n",
    "feedback = initial_feedback(idea=project_idea)\n",
    "\n",
    "# Print or handle the response\n",
    "print(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3674857",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_analyzer = ChainOfThought(\"feedback -> strengths, improvements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec669bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_analysis = feedback_analyzer(feedback=feedback)\n",
    "print(feedback_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5924d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea iterator:\n",
    "# Given an idea, with feedback from the UI, generate a new idea based on user input\n",
    "project_idea_iterator = ChainOfThought(\"project_idea, feedback -> improved_project_idea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Refinement Loop\n",
    "We will implement a refinement loop to allow the user to provide additional input and receive updated feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e197f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def43e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_idea_iterator(\n",
    "    project_idea=project_idea, feedback=\"This idea is too big. I only want a minimum viable project to show my boss.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    additional_input = input(\n",
    "        f\"\"\"\n",
    "                             Please provide additional input to refine your project idea (or type 'exit' to finish):\n",
    "                             {project_idea}\n",
    "                              \"\"\"\n",
    "    )\n",
    "    if not additional_input.strip():\n",
    "        new_idea = project_idea\n",
    "        break\n",
    "\n",
    "    new_idea = project_idea_iterator(project_idea=project_idea, feedback=additional_input)\n",
    "    project_idea = new_idea.improved_project_idea\n",
    "\n",
    "    print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c510147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Write a Short Style Guide\n",
    "\n",
    "In this step, we will write a short style guide summarizing the preferred coding style for the project, including type hinting, docstrings, and testability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style Guide\n",
    "\n",
    "#### Type Hinting\n",
    "- Use type hints for function arguments and return values.\n",
    "- Example:\n",
    "  ```python\n",
    "  def add(a: int, b: int) -> int:\n",
    "      return a + b\n",
    "  ```\n",
    "\n",
    "#### Docstrings\n",
    "- Use docstrings to document functions, classes, and modules.\n",
    "- Follow the Google style for docstrings.\n",
    "- Example:\n",
    "  ```python\n",
    "  def add(a: int, b: int) -> int:\n",
    "      \"\"\"Add two integers.\n",
    "\n",
    "      Args:\n",
    "          a (int): The first integer.\n",
    "          b (int): The second integer.\n",
    "\n",
    "      Returns:\n",
    "          int: The sum of the two integers.\n",
    "      \"\"\"\n",
    "      return a + b\n",
    "  ```\n",
    "\n",
    "#### Testability\n",
    "- Write testable code by following the principles of modularity and separation of concerns.\n",
    "- Use dependency injection to make code more testable.\n",
    "- Write unit tests for all functions and classes.\n",
    "- Example:\n",
    "  ```python\n",
    "  def add(a: int, b: int) -> int:\n",
    "      return a + b\n",
    "\n",
    "  def test_add():\n",
    "      assert add(1, 2) == 3\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Add an Agentic/Smolagents @tool to Review a File for a Certain Style Guide\n",
    "\n",
    "In this step, we will add an agentic/smolagents @tool to review a file for a certain style guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smoltools import tool\n",
    "import os\n",
    "\n",
    "\n",
    "@tool\n",
    "def review_file(file_path: str, style_guide: str) -> str:\n",
    "    \"\"\"Review a file for a certain style guide.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file to review.\n",
    "        style_guide (str): The style guide to review against.\n",
    "\n",
    "    Returns:\n",
    "        str: The review results.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Placeholder for actual review logic\n",
    "    review_results = f\"Reviewing {file_path} against {style_guide}...\\n\"\n",
    "    review_results += \"No issues found.\"\n",
    "\n",
    "    return review_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Include Prompt Templates to Execute the Reviews\n",
    "\n",
    "In this step, we will include prompt templates to execute the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a code reviewer. Your task is to review the following file for adherence to the specified style guide.\n",
    "\n",
    "File Path: {file_path}\n",
    "Style Guide: {style_guide}\n",
    "\n",
    "Please provide a detailed review, highlighting any issues and suggesting improvements.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_review_prompt(file_path: str, style_guide: str) -> str:\n",
    "    return prompt_template.format(file_path=file_path, style_guide=style_guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Demonstrate Example Review Results on a File\n",
    "\n",
    "In this step, we will demonstrate example review results on a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file_path = \"example.py\"\n",
    "example_style_guide = \"PEP 8\"\n",
    "\n",
    "review_results = review_file(example_file_path, example_style_guide)\n",
    "print(review_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Initialize a Tool from the Software Designer Tool System Prompt\n",
    "\n",
    "In this step, we will initialize a tool from the software designer tool system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smoltools import tool\n",
    "\n",
    "@tool\n",
    "def software_designer_tool(prompt: str) -> str:\n",
    "    \"\"\"Initialize a tool from the software designer tool system prompt.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The system prompt for the software designer tool.\n",
    "\n",
    "    Returns:\n",
    "        str: The initialized tool.\n",
    "    \"\"\"\n",
    "    # Placeholder for actual tool initialization logic\n",
    "    return f\"Tool initialized with prompt: {prompt}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: User Prompt to Create an Agentic Software Engineer for Coding Tasks\n",
    "\n",
    "In this step, we will write a user prompt to create an agentic software engineer for coding tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"\n",
    "You are an agentic software engineer. Your task is to assist with coding tasks, including generating markdown documentation, Python code files, performing smart web searches, and local document lookups.\n",
    "\n",
    "Please provide a detailed plan for the following coding task:\n",
    "\n",
    "Task: {task_description}\n",
    "\"\"\"\n",
    "\n",
    "def generate_user_prompt(task_description: str) -> str:\n",
    "    return user_prompt.format(task_description=task_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Enable the Software Engineer Agent to Generate Markdown Documentation, Python Code Files, Perform Smart Web Searches, and Local Document Lookups\n",
    "\n",
    "In this step, we will enable the software engineer agent to generate markdown documentation, Python code files, perform smart web searches, and local document lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smoltools import tool\n",
    "\n",
    "@tool\n",
    "def software_engineer_agent(task_description: str) -> str:\n",
    "    \"\"\"Enable the software engineer agent to generate markdown documentation, Python code files, perform smart web searches, and local document lookups.\n",
    "\n",
    "    Args:\n",
    "        task_description (str): The description of the coding task.\n",
    "\n",
    "    Returns:\n",
    "        str: The result of the coding task.\n",
    "    \"\"\"\n",
    "    # Placeholder for actual agent logic\n",
    "    return f\"Task completed: {task_description}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-chat-gpt-kernel",
   "language": "python",
   "name": "my-chat-gpt-kernel"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
