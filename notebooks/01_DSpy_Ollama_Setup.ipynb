{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_LangChain/DSpy Setup with Local Ollama Container Instance\n",
    "\n",
    "This notebook demonstrates how to set up LangChain and DSpy to work with a local Ollama container instance. We will cover the installation of necessary packages, configuration, and connection to the local Ollama instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install LangChain, DSpy, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (0.3.9)\n",
      "Requirement already satisfied: langchain_community in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain_ollama in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: dspy in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (2.5.41)\n",
      "Requirement already satisfied: requests in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (3.11.8)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (0.3.21)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (0.3.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (2.10.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_community) (2.6.1)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_ollama) (0.4.2)\n",
      "Requirement already satisfied: backoff in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (2.2.1)\n",
      "Requirement already satisfied: datasets in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (3.1.0)\n",
      "Requirement already satisfied: diskcache in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (5.6.3)\n",
      "Requirement already satisfied: httpx in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (0.27.2)\n",
      "Requirement already satisfied: joblib~=1.3 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (1.4.2)\n",
      "Requirement already satisfied: json-repair in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (0.30.2)\n",
      "Requirement already satisfied: litellm==1.51.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (1.51.0)\n",
      "Requirement already satisfied: magicattr~=0.1.6 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (0.1.6)\n",
      "Requirement already satisfied: openai in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (1.55.3)\n",
      "Requirement already satisfied: optuna in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (4.1.0)\n",
      "Requirement already satisfied: pandas in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (2.2.3)\n",
      "Requirement already satisfied: regex in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (4.67.1)\n",
      "Requirement already satisfied: ujson in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (5.10.0)\n",
      "Requirement already satisfied: anyio in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (4.6.2.post1)\n",
      "Requirement already satisfied: asyncer==0.0.8 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dspy) (0.0.8)\n",
      "Requirement already satisfied: click in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from litellm==1.51.0->dspy) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from litellm==1.51.0->dspy) (8.5.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from litellm==1.51.0->dspy) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from litellm==1.51.0->dspy) (4.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from litellm==1.51.0->dspy) (1.0.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from litellm==1.51.0->dspy) (0.8.0)\n",
      "Requirement already satisfied: tokenizers in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from litellm==1.51.0->dspy) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from anyio->dspy) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from httpx->dspy) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->dspy) (0.14.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from openai->dspy) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from openai->dspy) (0.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from tqdm->dspy) (0.4.6)\n",
      "Requirement already satisfied: filelock in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from datasets->dspy) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from datasets->dspy) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from datasets->dspy) (0.3.8)\n",
      "Requirement already satisfied: xxhash in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from datasets->dspy) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from datasets->dspy) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->dspy) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from datasets->dspy) (0.26.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from optuna->dspy) (1.14.0)\n",
      "Requirement already satisfied: colorlog in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from optuna->dspy) (6.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from pandas->dspy) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from pandas->dspy) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from pandas->dspy) (2024.2)\n",
      "Requirement already satisfied: Mako in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from alembic>=1.5.0->optuna->dspy) (1.3.6)\n",
      "Requirement already satisfied: zipp>=3.20 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from importlib-metadata>=6.8.0->litellm==1.51.0->dspy) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.51.0->dspy) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.51.0->dspy) (0.21.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->dspy) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\github\\pkuppens\\my_chat_gpt\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community langchain_ollama dspy requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Packages\n",
    "\n",
    "Next, we will import the necessary packages for our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\GitHub\\pkuppens\\my_chat_gpt\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy import ChainOfThought\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Connection to Local Ollama Instance\n",
    "\n",
    "We need to configure the connection to our local Ollama container instance. The following code sets up the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7dd6b",
   "metadata": {},
   "source": [
    "### Step 3.1: Setup Ollama Docker Container Instance\n",
    "\n",
    "*_Run the following step first. This step is only needed if the following step fails._*\n",
    "\n",
    "#### Ollama\n",
    "Ollama is a containerized environment for running and managing LLMs. It provides an API for interacting with the models.\n",
    "\n",
    "#### Setup Instructions\n",
    "1. Ensure Docker is installed and running on your machine.\n",
    "2. Check if there is a Docker container instance 'ollama' that can be (re-)started.\n",
    "3. _If no 'ollama' container exists_: Create and run a new Ollama container instance using the following command:\n",
    "   ```\n",
    "   docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n",
    "   ```\n",
    "4. Verify the Ollama instance is running by accessing [http://localhost:11434/api/version](http://localhost:11434/api/version).\n",
    "5. Verify programmatic connection by (re-)running the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Ollama version: {'version': '0.5.4-0-g2ddc32d-dirty'}\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_API_URL = \"http://localhost:11434/api\"\n",
    "\n",
    "def get_ollama_version():\n",
    "    response = requests.get(f\"{OLLAMA_API_URL}/version\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    ollama_version = get_ollama_version()\n",
    "    if ollama_version:\n",
    "        print(f\"Connected to Ollama version: {ollama_version}\")\n",
    "    else:\n",
    "        print(\"Failed to connect to Ollama instance.\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Failed to connect to Ollama instance, is the Docker container running?\")\n",
    "    input(\"Press Enter to continue...\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Minimal Documentation and Instructions\n",
    "\n",
    "### LangChain\n",
    "LangChain is a framework for building applications with large language models (LLMs). It provides tools and abstractions to simplify the development process.\n",
    "\n",
    "### DSpy\n",
    "DSpy is a data science library that offers various utilities for data manipulation, analysis, and visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate LangChain and DSpy Integration\n",
    "\n",
    "In this step, we will demonstrate how to use LangChain and DSpy together in a practical example. We will use LangChain to generate text and DSpy to analyze the generated text.\n",
    "\n",
    "### Example: Text Generation and Analysis\n",
    "\n",
    "1. Use LangChain to generate text based on a prompt.\n",
    "2. Use DSpy to analyze the generated text.\n",
    "\n",
    "#### Generate Text with LangChain\n",
    "We will use LangChain to generate text based on a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7eb3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str, nr_articles=3) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=nr_articles)\n",
    "    return [x['text'] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a025f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With new dspy version 2.5:\n",
    "import dspy\n",
    "\n",
    "lm = dspy.LM('ollama_chat/llama3.2', api_base='http://localhost:11434', api_key='')\n",
    "rm = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')  # retrieval model\n",
    "dspy.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f800f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are 10 potential song title ideas about infamous soccer players:\\n\\n1. \"The Devil\\'s in the Details\" (about Diego Maradona)\\n2. \"Red Card Rhapsody\" (about various players who have received red cards throughout history)\\n3. \"The Beautiful Game of Deceit\" (about players like Zinedine Zidane and Marco van Basten, known for their skill but also controversy)\\n4. \"Foul Play\" (about players like David Beckham and Ronaldinho, known for their aggressive play on the field)\\n5. \"The King\\'s Downfall\" (about Pelé, who was once considered a king of soccer but had his reputation tarnished by scandals)\\n6. \"Offside and Out\" (about players like Thierry Henry and Luis Suárez, who have been involved in high-profile controversies)\\n7. \"The Beautiful Game of Betrayal\" (about players like David Beckham and Cristiano Ronaldo, who have been accused of betraying their teams or country)\\n8. \"Kicking It Old School\" (about old-school soccer legends like George Best and Johan Cruyff)\\n9. \"The Dark Side of the Pitch\" (about players like Zlatan Ibrahimović and Mario Balotelli, known for their volatile personalities)\\n10. \"Soccer\\'s Shame\" (about players like John Terry and Ashley Cole, who have been involved in high-profile scandals off the field)\\n\\nThese titles are meant to be provocative and attention-grabbing, while also highlighting the complexities and controversies surrounding these infamous soccer players.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm('Come up with 10 names for a song about infamous soccer players')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47797fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_role = rm(\"Chief Executive Officer\", k=1)[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8260a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chief executive officer | A chief executive officer (CEO) is the position of the most senior corporate officer, executive, leader or administrator in charge of managing an organization. CEOs lead a range of organizations, including public and private corporations, non-profit organizations and even some government organizations (e.g., Crown corporations). The CEO of a corporation or company typically reports to the board of directors and is charged with maximizing the value of the entity, which may include maximizing the share price, market share, revenues, or another element. In the non-profit and government sector, CEOs typically aim at achieving outcomes related to the organization's mission, such as reducing poverty, increasing literacy, etc. Titles also often given to the holder of CEO position include president, chief executive (CE), and managing director (MD), as well as representative director (RD) in Japan.\n"
     ]
    }
   ],
   "source": [
    "print(ceo_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/)\n",
    "- [DSpy Documentation](https://dspy.ai/tutorials/rag/)\n",
    "- [LangChain and DSpy Integration](https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: BasicQA DSpy Example with Signature Class\n",
    "\n",
    "In this step, we will demonstrate a zero-shot example using DSpy and dspy.Signature class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e06321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?\n",
      "Answer: Paris\n"
     ]
    }
   ],
   "source": [
    "# Define the signature for the QA task\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "# Initialize the Predict module with the signature\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Provide a question to the model\n",
    "response = generate_answer(question=\"What is the capital of France?\")\n",
    "\n",
    "# Output the answer\n",
    "print(f\"Question: What is the capital of France?\")\n",
    "print(f\"Answer: {response.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: User Input for Software Project Idea\n",
    "\n",
    "In this step, we will prompt the user to write a software project idea, send it to the LLM, and display the feedback, summary, and plan.\n",
    "\n",
    "### Example: User Input and Feedback Loop\n",
    "\n",
    "1. Prompt the user to write a software project idea.\n",
    "2. Send the idea to the LLM and display the feedback, summary, and plan.\n",
    "3. Implement a refinement loop to allow the user to provide additional input and receive updated feedback.\n",
    "\n",
    "#### Prompt User for Software Project Idea\n",
    "We will prompt the user to write a software project idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Get user input for software project idea, default to \n",
    "project_idea = input(\"Please write your software project idea: \") or \"Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\"\n",
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44bca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The AI software factory will utilize Large Language Model (LLM) Agents to implement step-by-step software processes, ensuring efficient and effective project execution. This approach leverages the capabilities of LLMs in natural language processing, machine learning, and knowledge representation, allowing for the automation of complex software development tasks.',\n",
      "    feedback='The proposed AI software factory will provide numerous benefits, including increased productivity, improved accuracy, and enhanced scalability. By automating repetitive and time-consuming tasks, developers can focus on higher-level creative work, leading to innovative solutions and faster project delivery. Additionally, the use of LLM Agents ensures consistency and reliability across projects, reducing the risk of human error.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a custom chain that uses a single-step prompt\n",
    "# but instructs the model to produce the summary, strengths, and improvement_areas in one go.\n",
    "initial_feedback = ChainOfThought(\n",
    "    'idea -> feedback'\n",
    ")\n",
    "\n",
    "# Call the chain\n",
    "feedback = initial_feedback(idea=project_idea)\n",
    "\n",
    "# Print or handle the response\n",
    "print(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3674857",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_analyzer = ChainOfThought(\n",
    "    'feedback -> strengths, improvements'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec669bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The AI software factory will utilize Large Language Model (LLM) Agents to implement step-by-step software processes, ensuring efficient and effective project execution. This approach leverages the capabilities of LLMs in natural language processing, machine learning, and knowledge representation, allowing for the automation of complex software development tasks.',\n",
      "    strengths='Increased productivity, improved accuracy, enhanced scalability, automation of repetitive and time-consuming tasks, consistency and reliability across projects, reduced risk of human error.',\n",
      "    improvements='None specified'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "feedback_analysis = feedback_analyzer(feedback=feedback)\n",
    "print(feedback_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5924d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea iterator:\n",
    "# Given an idea, with feedback from the UI, generate a new idea based on user input\n",
    "project_idea_iterator = ChainOfThought(\n",
    "    'project_idea, feedback -> improved_project_idea'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Refinement Loop\n",
    "We will implement a refinement loop to allow the user to provide additional input and receive updated feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e197f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n"
     ]
    }
   ],
   "source": [
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "def43e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The initial project idea is too broad and ambitious, requiring significant resources to implement. To make it more feasible, we need to scale down the scope of the project.',\n",
       "    improved_project_idea='A minimum viable prototype (MVP) that demonstrates the core functionality of the AI software factory, focusing on a smaller subset of features and functionalities.'\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_idea_iterator(project_idea=project_idea, feedback='This idea is too big. I only want a minimum viable project to show my boss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A simplified version of the AI software factory concept, focusing on creating an MVP with tangible deliverables, such as:\n",
      "\n",
      "* A prototype for the AI software factory\n",
      "* Concrete item requirements for the project\n",
      "* Step-by-step software processes implemented by LLM Agents\n",
      "An improved version of the AI software factory concept could include:\n",
      "- A more detailed prototype that showcases the capabilities of the AI software factory\n",
      "- Enhanced item requirements that account for varying project complexities\n",
      "- Automated testing frameworks for LLM Agents\n",
      "\n",
      "These improvements would increase the value and practicality of the MVP, making it a more effective tool for teams to develop and deploy AI-powered software.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    additional_input = input(f\"\"\"\n",
    "                             Please provide additional input to refine your project idea (or type 'exit' to finish):\n",
    "                             {project_idea}\n",
    "                              \"\"\")\n",
    "    if not additional_input.strip():\n",
    "        new_idea = project_idea\n",
    "        break\n",
    "    \n",
    "    new_idea = project_idea_iterator(project_idea=project_idea, feedback=additional_input)\n",
    "    project_idea = new_idea.improved_project_idea\n",
    "    \n",
    "    print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c510147b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An improved version of the AI software factory concept could include:\\n- A more detailed prototype that showcases the capabilities of the AI software factory\\n- Enhanced item requirements that account for varying project complexities\\n- Automated testing frameworks for LLM Agents\\n\\nThese improvements would increase the value and practicality of the MVP, making it a more effective tool for teams to develop and deploy AI-powered software.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_idea\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
