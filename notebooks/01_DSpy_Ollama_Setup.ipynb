{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_LangChain/DSpy Setup with Local Ollama Container Instance\n",
    "\n",
    "This notebook demonstrates how to set up LangChain and DSpy to work with a local Ollama container instance. We will cover the installation of necessary packages, configuration, and connection to the local Ollama instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install LangChain, DSpy, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain_community langchain_ollama dspy requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Packages\n",
    "\n",
    "Next, we will import the necessary packages for our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy import ChainOfThought\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Connection to Local Ollama Instance\n",
    "\n",
    "We need to configure the connection to our local Ollama container instance. The following code sets up the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7dd6b",
   "metadata": {},
   "source": [
    "### Step 3.1: Setup Ollama Docker Container Instance\n",
    "\n",
    "*_Run the following step first. This step is only needed if the following step fails._*\n",
    "\n",
    "#### Ollama\n",
    "Ollama is a containerized environment for running and managing LLMs. It provides an API for interacting with the models.\n",
    "\n",
    "#### Setup Instructions\n",
    "1. Ensure Docker is installed and running on your machine.\n",
    "2. Check if there is a Docker container instance 'ollama' that can be (re-)started.\n",
    "3. _If no 'ollama' container exists_: Create and run a new Ollama container instance using the following command:\n",
    "   ```\n",
    "   docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n",
    "   ```\n",
    "4. Verify the Ollama instance is running by accessing [http://localhost:11434/api/version](http://localhost:11434/api/version).\n",
    "5. Verify programmatic connection by (re-)running the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Ollama version: {'version': '0.3.13'}\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_API_URL = \"http://localhost:11434/api\"\n",
    "\n",
    "def get_ollama_version():\n",
    "    response = requests.get(f\"{OLLAMA_API_URL}/version\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    ollama_version = get_ollama_version()\n",
    "    if ollama_version:\n",
    "        print(f\"Connected to Ollama version: {ollama_version}\")\n",
    "    else:\n",
    "        print(\"Failed to connect to Ollama instance.\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Failed to connect to Ollama instance, is the Docker container running?\")\n",
    "    input(\"Press Enter to continue...\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Minimal Documentation and Instructions\n",
    "\n",
    "### LangChain\n",
    "LangChain is a framework for building applications with large language models (LLMs). It provides tools and abstractions to simplify the development process.\n",
    "\n",
    "### DSpy\n",
    "DSpy is a data science library that offers various utilities for data manipulation, analysis, and visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate LangChain and DSpy Integration\n",
    "\n",
    "In this step, we will demonstrate how to use LangChain and DSpy together in a practical example. We will use LangChain to generate text and DSpy to analyze the generated text.\n",
    "\n",
    "### Example: Text Generation and Analysis\n",
    "\n",
    "1. Use LangChain to generate text based on a prompt.\n",
    "2. Use DSpy to analyze the generated text.\n",
    "\n",
    "#### Generate Text with LangChain\n",
    "We will use LangChain to generate text based on a given prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7eb3363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_wikipedia(query: str, nr_articles=3) -> list[str]:\n",
    "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=nr_articles)\n",
    "    return [x['text'] for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a025f06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With new dspy version 2.5:\n",
    "import dspy\n",
    "\n",
    "lm = dspy.LM('ollama_chat/llama3.2', api_base='http://localhost:11434', api_key='')\n",
    "rm = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')  # retrieval model\n",
    "dspy.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f800f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here are 10 potential song title ideas about infamous soccer players:\\n\\n1. \"The Devil\\'s in the Details\" (about Diego Maradona)\\n2. \"Red Card Rhapsody\" (about various players who have received red cards throughout history)\\n3. \"The Beautiful Game of Deceit\" (about players like Zinedine Zidane and Marco van Basten, known for their skillful but sometimes questionable tactics)\\n4. \"Foul Play\" (about players like Ronaldinho and Thierry Henry, infamous for their diving and other forms of cheating)\\n5. \"The King\\'s Downfall\" (about the rise and fall of famous soccer players like Cristiano Ronaldo or Lionel Messi)\\n6. \"Offside and Out\" (about players who have been involved in high-profile controversies, such as Luis Suarez or Mario Balotelli)\\n7. \"The Beautiful Lie\" (about the myth surrounding players like PelÃ© or Johan Cruyff, whose on-field performances were often shrouded in controversy)\\n8. \"Kicking It Old School\" (about classic soccer players like George Best or Bobby Charlton, who were known for their skill and showmanship)\\n9. \"The Dark Side of the Pitch\" (about players who have been involved in scandals or controversies off the field, such as David Beckham or John Terry)\\n10. \"Tackling the Truth\" (about players who have been accused of cheating or other forms of misconduct, such as Javier Mascherano or Frank Lampard)\\n\\nI hope these ideas spark some inspiration for your song!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm('Come up with 10 names for a song about infamous soccer players')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47797fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ceo_role = rm(\"Chief Executive Officer\", k=1)[0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8260a8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chief executive officer | A chief executive officer (CEO) is the position of the most senior corporate officer, executive, leader or administrator in charge of managing an organization. CEOs lead a range of organizations, including public and private corporations, non-profit organizations and even some government organizations (e.g., Crown corporations). The CEO of a corporation or company typically reports to the board of directors and is charged with maximizing the value of the entity, which may include maximizing the share price, market share, revenues, or another element. In the non-profit and government sector, CEOs typically aim at achieving outcomes related to the organization's mission, such as reducing poverty, increasing literacy, etc. Titles also often given to the holder of CEO position include president, chief executive (CE), and managing director (MD), as well as representative director (RD) in Japan.\n"
     ]
    }
   ],
   "source": [
    "print(ceo_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/)\n",
    "- [DSpy Documentation](https://dspy.ai/tutorials/rag/)\n",
    "- [LangChain and DSpy Integration](https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: BasicQA DSpy Example with Signature Class\n",
    "\n",
    "In this step, we will demonstrate a zero-shot example using DSpy and dspy.Signature class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e06321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is the capital of France?\n",
      "Answer: Paris\n"
     ]
    }
   ],
   "source": [
    "# Define the signature for the QA task\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "# Initialize the Predict module with the signature\n",
    "generate_answer = dspy.Predict(BasicQA)\n",
    "\n",
    "# Provide a question to the model\n",
    "response = generate_answer(question=\"What is the capital of France?\")\n",
    "\n",
    "# Output the answer\n",
    "print(f\"Question: What is the capital of France?\")\n",
    "print(f\"Answer: {response.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: User Input for Software Project Idea\n",
    "\n",
    "In this step, we will prompt the user to write a software project idea, send it to the LLM, and display the feedback, summary, and plan.\n",
    "\n",
    "### Example: User Input and Feedback Loop\n",
    "\n",
    "1. Prompt the user to write a software project idea.\n",
    "2. Send the idea to the LLM and display the feedback, summary, and plan.\n",
    "3. Implement a refinement loop to allow the user to provide additional input and receive updated feedback.\n",
    "\n",
    "#### Prompt User for Software Project Idea\n",
    "We will prompt the user to write a software project idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Get user input for software project idea, default to \n",
    "project_idea = input(\"Please write your software project idea: \") or \"Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\"\n",
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c44bca2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The AI software factory will utilize Large Language Model (LLM) Agents to implement step-by-step software processes, ensuring efficient and effective project execution. This approach leverages the capabilities of LLMs in natural language processing, machine learning, and knowledge representation, allowing for the automation of complex software development tasks.',\n",
      "    feedback='The proposed AI software factory will provide numerous benefits, including increased productivity, improved accuracy, and enhanced scalability. By automating repetitive and time-consuming tasks, developers can focus on higher-level creative work, leading to innovative solutions and faster project delivery. Additionally, the use of LLM Agents ensures consistency and reliability across projects, reducing the risk of human error.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a custom chain that uses a single-step prompt\n",
    "# but instructs the model to produce the summary, strengths, and improvement_areas in one go.\n",
    "initial_feedback = ChainOfThought(\n",
    "    'idea -> feedback'\n",
    ")\n",
    "\n",
    "# Call the chain\n",
    "feedback = initial_feedback(idea=project_idea)\n",
    "\n",
    "# Print or handle the response\n",
    "print(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3674857",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_analyzer = ChainOfThought(\n",
    "    'feedback -> strengths, improvements'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec669bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The AI software factory will utilize Large Language Model (LLM) Agents to implement step-by-step software processes, ensuring efficient and effective project execution. This approach leverages the capabilities of LLMs in natural language processing, machine learning, and knowledge representation, allowing for the automation of complex software development tasks.',\n",
      "    strengths='The proposed AI software factory will provide numerous benefits, including increased productivity, improved accuracy, and enhanced scalability. By automating repetitive and time-consuming tasks, developers can focus on higher-level creative work, leading to innovative solutions and faster project delivery. Additionally, the use of LLM Agents ensures consistency and reliability across projects, reducing the risk of human error.',\n",
      "    improvements='There are no specific areas mentioned for improvement in the provided feedback. However, potential areas for future development could include ensuring seamless integration with existing software systems, addressing potential biases in LLMs, and providing more detailed documentation and training for developers to effectively utilize the AI software factory.'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "feedback_analysis = feedback_analyzer(feedback=feedback)\n",
    "print(feedback_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5924d1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea iterator:\n",
    "# Given an idea, with feedback from the UI, generate a new idea based on user input\n",
    "project_idea_iterator = ChainOfThought(\n",
    "    'project_idea, feedback -> improved_project_idea'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement Refinement Loop\n",
    "We will implement a refinement loop to allow the user to provide additional input and receive updated feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1e197f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n"
     ]
    }
   ],
   "source": [
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "def43e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The initial project idea is too broad and ambitious, requiring significant resources to implement. To make it more feasible, we need to scale down the scope of the project.',\n",
       "    improved_project_idea='A minimum viable prototype (MVP) that demonstrates the core functionality of the AI software factory, focusing on a smaller subset of features and functionalities.'\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_idea_iterator(project_idea=project_idea, feedback='This idea is too big. I only want a minimum viable project to show my boss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    additional_input = input(f\"\"\"\n",
    "                             Please provide additional input to refine your project idea (or type 'exit' to finish):\n",
    "                             {project_idea}\n",
    "                              \"\"\")\n",
    "    if not additional_input.strip():\n",
    "        new_idea = project_idea\n",
    "        break\n",
    "    \n",
    "    new_idea = project_idea_iterator(project_idea=project_idea, feedback=additional_input)\n",
    "    project_idea = new_idea.improved_project_idea\n",
    "    \n",
    "    print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c510147b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_idea\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Write a Short Style Guide\n",
    "\n",
    "In this step, we will write a short style guide summarizing the preferred coding style for the project, including type hinting, docstrings, and testability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Style Guide\n",
    "\n",
    "#### Type Hinting\n",
    "- Use type hints for function arguments and return values.\n",
    "- Example:\n",
    "  ```python\n",
    "  def add(a: int, b: int) -> int:\n",
    "      return a + b\n",
    "  ```\n",
    "\n",
    "#### Docstrings\n",
    "- Use docstrings to document functions, classes, and modules.\n",
    "- Follow the Google style for docstrings.\n",
    "- Example:\n",
    "  ```python\n",
    "  def add(a: int, b: int) -> int:\n",
    "      \"\"\"Add two integers.\n",
    "\n",
    "      Args:\n",
    "          a (int): The first integer.\n",
    "          b (int): The second integer.\n",
    "\n",
    "      Returns:\n",
    "          int: The sum of the two integers.\n",
    "      \"\"\"\n",
    "      return a + b\n",
    "  ```\n",
    "\n",
    "#### Testability\n",
    "- Write testable code by following the principles of modularity and separation of concerns.\n",
    "- Use dependency injection to make code more testable.\n",
    "- Write unit tests for all functions and classes.\n",
    "- Example:\n",
    "  ```python\n",
    "  def add(a: int, b: int) -> int:\n",
    "      return a + b\n",
    "\n",
    "  def test_add():\n",
    "      assert add(1, 2) == 3\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Add an Agentic/Smolagents @tool to Review a File for a Certain Style Guide\n",
    "\n",
    "In this step, we will add an agentic/smolagents @tool to review a file for a certain style guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smoltools import tool\n",
    "import os\n",
    "\n",
    "@tool\n",
    "def review_file(file_path: str, style_guide: str) -> str:\n",
    "    \"\"\"Review a file for a certain style guide.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file to review.\n",
    "        style_guide (str): The style guide to review against.\n",
    "\n",
    "    Returns:\n",
    "        str: The review results.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Placeholder for actual review logic\n",
    "    review_results = f\"Reviewing {file_path} against {style_guide}...\\n\"\n",
    "    review_results += \"No issues found.\"\n",
    "\n",
    "    return review_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Include Prompt Templates to Execute the Reviews\n",
    "\n",
    "In this step, we will include prompt templates to execute the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are a code reviewer. Your task is to review the following file for adherence to the specified style guide.\n",
    "\n",
    "File Path: {file_path}\n",
    "Style Guide: {style_guide}\n",
    "\n",
    "Please provide a detailed review, highlighting any issues and suggesting improvements.\n",
    "\"\"\"\n",
    "\n",
    "def generate_review_prompt(file_path: str, style_guide: str) -> str:\n",
    "    return prompt_template.format(file_path=file_path, style_guide=style_guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Demonstrate Example Review Results on a File\n",
    "\n",
    "In this step, we will demonstrate example review results on a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviewing example.py against PEP 8...\n",
      "No issues found.\n"
     ]
    }
   ],
   "source": [
    "example_file_path = \"example.py\"\n",
    "example_style_guide = \"PEP 8\"\n",
    "\n",
    "review_results = review_file(example_file_path, example_style_guide)\n",
    "print(review_results)"
   ]
  }
 ]
}
