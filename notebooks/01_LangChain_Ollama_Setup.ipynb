{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_LangChain Setup with Local Ollama Container Instance\n",
    "\n",
    "This notebook demonstrates how to set up LangChain to work with a local Ollama container instance.\n",
    "We will cover the installation of necessary packages, configuration, and connection to the local Ollama instance.\n",
    "This could be useful for using LangChain/LangFlow like techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install LangChain dependencies.\n",
    "\n",
    "Typically, this is already done with a `pip install -r requirements.txt`, and is only needed once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain_community langchain_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Packages\n",
    "\n",
    "Next, we will import the necessary packages for our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Connection to Local Ollama Instance\n",
    "\n",
    "We need to configure the connection to our local Ollama container instance. The following code sets up the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7dd6b",
   "metadata": {},
   "source": [
    "### Step 3.1: Setup Ollama Docker Container Instance\n",
    "\n",
    "*_Run the following step first. This step is only needed if the following step fails._*\n",
    "\n",
    "#### Ollama\n",
    "Ollama is a containerized environment for running and managing LLMs. It provides an API for interacting with the models.\n",
    "\n",
    "#### Setup Instructions\n",
    "1. Ensure Docker is installed and running on your machine.\n",
    "2. Check if there is a Docker container instance 'ollama' that can be (re-)started.\n",
    "3. _If no 'ollama' container exists_: Create and run a new Ollama container instance using the following command:\n",
    "   ```\n",
    "   docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n",
    "   ```\n",
    "4. Verify the Ollama instance is running by accessing [http://localhost:11434/api/version](http://localhost:11434/api/version).\n",
    "5. Verify programmatic connection by (re-)running the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Ollama version: {'version': '0.3.13'}\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_API_URL = \"http://localhost:11434/api\"\n",
    "\n",
    "def get_ollama_version():\n",
    "    response = requests.get(f\"{OLLAMA_API_URL}/version\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    ollama_version = get_ollama_version()\n",
    "    if ollama_version:\n",
    "        print(f\"Connected to Ollama version: {ollama_version}\")\n",
    "    else:\n",
    "        print(\"Failed to connect to Ollama instance.\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Failed to connect to Ollama instance, is the Docker container running?\")\n",
    "    input(\"Press Enter to continue...\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Minimal Documentation and Instructions\n",
    "\n",
    "### LangChain\n",
    "LangChain is a framework for building applications with large language models (LLMs). It provides tools and abstractions to simplify the development process.\n",
    "\n",
    "https://python.langchain.com/docs/tutorials/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate LangChain\n",
    "\n",
    "In this step, we will demonstrate basic LangChain usage.\n",
    "\n",
    "### Example: Text Generation\n",
    "\n",
    "Use LangChain to generate text based on a prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd55e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are ten potential song title ideas about parrots:\\n\\n1. \"Rainbow Wings\"\\n2. \"Parrot\\'s Lament\"\\n3. \"Squawk of the Wild\"\\n4. \"Blue and Green Eyes\"\\n5. \"Flock to the Sky\"\\n6. \"Love in Full Plumage\"\\n7. \"The Parrot\\'s Songbook\"\\n8. \"Colorful Dreams\"\\n9. \"A Bird with a View\"\\n10. \"Sunset Scales\"\\n\\nThese titles aim to capture the vibrant colors, playful personalities, and captivating songs of parrots, while also exploring themes of freedom, beauty, and connection.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "generated_text = model.invoke(\"Come up with 10 names for a song about parrots\")\n",
    "\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/)\n",
    "\n",
    "### Furture Work Suggestion\n",
    "\n",
    "- [LangChain and DSpy Integration](https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: User Input for Software Project Idea Using LangChain\n",
    "\n",
    "In this step, we will prompt the user to write a software project idea, send it to the LLM, and display the feedback, summary, and plan.\n",
    "\n",
    "### Example: User Input and Feedback Loop\n",
    "\n",
    "1. Prompt the user to write a software project idea.\n",
    "2. Send the idea to the LLM and display the feedback, summary, and plan.\n",
    "3. Implement a refinement loop to allow the user to provide additional input and receive updated feedback.\n",
    "\n",
    "#### Prompt User for Software Project Idea\n",
    "We will prompt the user to write a software project idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Get user input for software project idea, default to \n",
    "project_idea = input(\"Please write your software project idea: \") or \"Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\"\n",
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad572389",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"A user came up with a project idea: {project_idea}\n",
    "\n",
    "The user wants to know what the project would look like if it was implemented.\n",
    "\n",
    "Write a short description of the project, including the main features and how it would work.\n",
    "\n",
    "Then give your feedback on the project idea, including any suggestions for improvement, or\n",
    "areas that may need clarification.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7efb73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A user came up with a project idea: Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n",
      "\n",
      "The user wants to know what the project would look like if it was implemented.\n",
      "\n",
      "Write a short description of the project, including the main features and how it would work.\n",
      "\n",
      "Then give your feedback on the project idea, including any suggestions for improvement, or\n",
      "areas that may need clarification.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_prompt = prompt_template.format(project_idea=project_idea)\n",
    "print(filled_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43805f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project Description:\n",
      "\n",
      "Project Name: AI Software Factory (ASF)\n",
      "\n",
      "The AI Software Factory is an innovative platform that utilizes Large Language Model (LLM) Agents to generate software from project ideas. The ASF will consist of a step-by-step software development process implemented by the LLM Agents, which will guide users through the creation of their desired software product.\n",
      "\n",
      "Main Features:\n",
      "\n",
      "1. Project Idea Input: Users will input their project idea into the system, and the LLM Agent will analyze it to identify key features, requirements, and potential technologies.\n",
      "2. Software Process Planning: The LLM Agent will create a customized software development process plan based on the user's input, outlining tasks, milestones, and deadlines.\n",
      "3. Automated Code Generation: Using natural language processing (NLP) and machine learning algorithms, the LLM Agent will generate code for each task in the process plan, following industry-standard programming languages and best practices.\n",
      "4. Integration with Development Tools: The generated code will be integrated with development tools such as IDEs, version control systems, and testing frameworks to facilitate seamless development and deployment.\n",
      "5. Continuous Monitoring and Feedback: The LLM Agent will continuously monitor the project's progress, providing real-time feedback and suggestions for improvement to ensure timely completion and high-quality software delivery.\n",
      "\n",
      "How it Would Work:\n",
      "\n",
      "1. User inputs their project idea into the system.\n",
      "2. The LLM Agent analyzes the input and creates a customized software development process plan.\n",
      "3. The LLM Agent generates code based on the process plan, which is then integrated with development tools.\n",
      "4. Users work on implementing the generated code, following the guidance provided by the LLM Agent.\n",
      "5. As users complete each task, the LLM Agent reviews and provides feedback, adjusting the process plan as needed.\n",
      "\n",
      "Feedback:\n",
      "\n",
      "The project idea of creating an AI software factory using LLM Agents is innovative and promising. Here are some suggestions for improvement and areas that may need clarification:\n",
      "\n",
      "1. **Scope and Limitations**: While the concept is exciting, it's essential to define clear scope and limitations for the ASF. What types of projects can it handle? How much complexity will it be able to handle? Establishing these boundaries will help manage expectations and ensure successful project implementation.\n",
      "2. **LLM Agent Capabilities**: The LLM Agent's capabilities are crucial to the success of the ASF. It should be able to accurately analyze project ideas, generate high-quality code, and provide effective guidance throughout the development process. Clarifying the LLM Agent's strengths, weaknesses, and potential biases will help users understand its limitations.\n",
      "3. **User Interface and Experience**: The user interface should be intuitive, easy to use, and provide a seamless experience for users. Consider incorporating features like project templates, code review, and collaboration tools to enhance user engagement and productivity.\n",
      "4. **Integration with Existing Tools**: While the ASF aims to integrate with development tools, it's crucial to ensure compatibility with various existing systems and frameworks. Investigating potential integration challenges and developing strategies for resolving them will be essential.\n",
      "5. **Ethics and Intellectual Property**: The use of AI-generated code raises concerns about intellectual property rights and ownership. Establishing clear guidelines and policies regarding the usage of generated code will be necessary to address these concerns.\n",
      "\n",
      "Overall, the project idea has tremendous potential, but addressing these areas will help refine the concept and ensure its successful implementation.\n"
     ]
    }
   ],
   "source": [
    "project_idea_feedback = model.invoke(filled_prompt)\n",
    "print(project_idea_feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Implement Refinement Loop\n",
    "\n",
    "We will implement a refinement loop to allow the user to provide additional input and receive updated feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    additional_input = input(f\"\"\"\n",
    "                             Please provide additional input to refine your project idea (or type 'exit' to finish):\n",
    "                             \n",
    "                             {project_idea}\n",
    "                             \"\"\")\n",
    "    if not additional_input.strip():\n",
    "        break\n",
    "\n",
    "    refinement_prompt_template = \"\"\"\n",
    "    You are an AI assistant. The user has provided a project description and additional input to refine the project idea.\n",
    "    Provide an updated project description that addresses the user's input.\n",
    "\n",
    "    {project_idea}\n",
    "\n",
    "    Additional Input: {additional_input}\n",
    "    \"\"\"\n",
    "    \n",
    "    refinement_prompt = refinement_prompt_template.format(project_idea=project_idea, additional_input=additional_input)\n",
    "    updated_feedback_summary_plan = model.invoke(refinement_prompt)\n",
    "    print(updated_feedback_summary_plan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
