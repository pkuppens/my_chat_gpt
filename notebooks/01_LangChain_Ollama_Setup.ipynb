{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_LangChain Setup with Local Ollama Container Instance\n",
    "\n",
    "This notebook demonstrates how to set up LangChain to work with a local Ollama container instance.\n",
    "We will cover the installation of necessary packages, configuration, and connection to the local Ollama instance.\n",
    "This could be useful for using LangChain/LangFlow like techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install LangChain dependencies.\n",
    "\n",
    "Typically, this is already done with a `pip install -r requirements.txt`, and is only needed once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: langchain_ollama in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (0.3.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (0.3.4)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_community) (2.7.0)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain_ollama) (0.4.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\piete\\repos\\my_chat_gpt\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain_community langchain_ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Packages\n",
    "\n",
    "Next, we will import the necessary packages for our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Connection to Local Ollama Instance\n",
    "\n",
    "We need to configure the connection to our local Ollama container instance. The following code sets up the connection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f7dd6b",
   "metadata": {},
   "source": [
    "### Step 3.1: Setup Ollama Docker Container Instance\n",
    "\n",
    "*_Run the following step first. This step is only needed if the following step fails._*\n",
    "\n",
    "#### Ollama\n",
    "Ollama is a containerized environment for running and managing LLMs. It provides an API for interacting with the models.\n",
    "\n",
    "#### Setup Instructions\n",
    "1. Ensure Docker is installed and running on your machine.\n",
    "2. Check if there is a Docker container instance 'ollama' that can be (re-)started.\n",
    "3. _If no 'ollama' container exists_: Create and run a new Ollama container instance using the following command:\n",
    "   ```\n",
    "   docker run -d --gpus=all -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n",
    "   ```\n",
    "4. Verify the Ollama instance is running by accessing [http://localhost:11434/api/version](http://localhost:11434/api/version).\n",
    "5. Verify programmatic connection by (re-)running the following cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Ollama version: {'version': '0.3.13'}\n"
     ]
    }
   ],
   "source": [
    "OLLAMA_API_URL = \"http://localhost:11434/api\"\n",
    "\n",
    "def get_ollama_version():\n",
    "    response = requests.get(f\"{OLLAMA_API_URL}/version\")\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "try:\n",
    "    ollama_version = get_ollama_version()\n",
    "    if ollama_version:\n",
    "        print(f\"Connected to Ollama version: {ollama_version}\")\n",
    "    else:\n",
    "        print(\"Failed to connect to Ollama instance.\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"Failed to connect to Ollama instance, is the Docker container running?\")\n",
    "    input(\"Press Enter to continue...\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Minimal Documentation and Instructions\n",
    "\n",
    "### LangChain\n",
    "LangChain is a framework for building applications with large language models (LLMs). It provides tools and abstractions to simplify the development process.\n",
    "\n",
    "https://python.langchain.com/docs/tutorials/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Demonstrate LangChain\n",
    "\n",
    "In this step, we will demonstrate basic LangChain usage.\n",
    "\n",
    "### Example: Text Generation\n",
    "\n",
    "Use LangChain to generate text based on a prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd55e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are 10 potential song title ideas about parrots:\\n\\n1. \"Colorful Wings\"\\n2. \"Parrot\\'s Lament\"\\n3. \"Flock to Me\"\\n4. \"Rainbow in the Sky\"\\n5. \"Squawk of Love\"\\n6. \"Tropical State of Mind\"\\n7. \"Polly\\'s Song\"\\n8. \"Green and Blue and Free\"\\n9. \"Flight of Fancy\"\\n10. \"Birds of Paradise Found\"\\n\\nThese titles aim to capture the vibrant colors, playful personalities, and exotic sounds of parrots, while also evoking a sense of wonder and freedom. Feel free to pick the one that inspires you the most!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"llama3.2\")\n",
    "generated_text = model.invoke(\"Come up with 10 names for a song about parrots\")\n",
    "\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/)\n",
    "\n",
    "### Furture Work Suggestion\n",
    "\n",
    "- [LangChain and DSpy Integration](https://www.reddit.com/r/LangChain/comments/1cqexk6/thoughts_on_dspy/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: User Input for Software Project Idea Using LangChain\n",
    "\n",
    "In this step, we will prompt the user to write a software project idea, send it to the LLM, and display the feedback, summary, and plan.\n",
    "\n",
    "### Example: User Input and Feedback Loop\n",
    "\n",
    "1. Prompt the user to write a software project idea.\n",
    "2. Send the idea to the LLM and display the feedback, summary, and plan.\n",
    "3. Implement a refinement loop to allow the user to provide additional input and receive updated feedback.\n",
    "\n",
    "#### Prompt User for Software Project Idea\n",
    "We will prompt the user to write a software project idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Get user input for software project idea, default to \n",
    "project_idea = input(\"Please write your software project idea: \") or \"Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\"\n",
    "print(project_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad572389",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"A user came up with a project idea: {project_idea}\n",
    "\n",
    "The user wants to know what the project would look like if it was implemented.\n",
    "\n",
    "Write a short description of the project, including the main features and how it would work.\n",
    "\n",
    "Then give your feedback on the project idea, including any suggestions for improvement, or\n",
    "areas that may need clarification.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7efb73e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A user came up with a project idea: Create an AI software factory that generates software from project ideas, using step-by-step software processes that are implemented by LLM Agents.\n",
      "\n",
      "The user wants to know what the project would look like if it was implemented.\n",
      "\n",
      "Write a short description of the project, including the main features and how it would work.\n",
      "\n",
      "Then give your feedback on the project idea, including any suggestions for improvement, or\n",
      "areas that may need clarification.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filled_prompt = prompt_template.format(project_idea=project_idea)\n",
    "print(filled_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43805f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Project Description:**\n",
      "\n",
      "The AI Software Factory project is an innovative software development platform that leverages Large Language Model (LLM) Agents to generate software from project ideas. The platform consists of a step-by-step software process framework that guides the LLM Agents in creating high-quality software products.\n",
      "\n",
      "Here's an overview of how it would work:\n",
      "\n",
      "1. **Project Idea Input**: Users submit their project ideas, including requirements, specifications, and any relevant data.\n",
      "2. **Analysis and Assessment**: The AI Software Factory analyzes the project idea, identifying key features, technical requirements, and potential challenges.\n",
      "3. **LLM Agent Implementation**: The platform deploys LLM Agents to implement the software process framework, using natural language processing (NLP) and machine learning algorithms to generate code.\n",
      "4. **Software Generation**: The LLM Agents create a functional software product based on the project idea, incorporating features such as design patterns, architecture, and testing protocols.\n",
      "5. **Review and Iteration**: Human reviewers inspect the generated software, providing feedback and suggestions for improvement.\n",
      "6. **Deployment and Maintenance**: The final software product is deployed to production environments, with ongoing maintenance and updates performed by human developers or AI Agents.\n",
      "\n",
      "**Main Features:**\n",
      "\n",
      "* Step-by-step software process framework\n",
      "* LLM Agent implementation for code generation\n",
      "* NLP and machine learning algorithms for analysis and assessment\n",
      "* Human review and iteration for quality control\n",
      "* Automated deployment and maintenance\n",
      "\n",
      "**Feedback and Suggestions:**\n",
      "\n",
      "The project idea has a lot of potential, but there are some areas that may require clarification or further development:\n",
      "\n",
      "1. **Scalability**: How will the platform handle large-scale projects with complex requirements? Will it be able to scale up to meet the demands of enterprise-level software development?\n",
      "2. **Quality Control**: While human review and iteration are essential for quality control, how will the platform ensure that generated code meets industry standards and best practices?\n",
      "3. **Customization**: How flexible is the platform in terms of customizing the software process framework or LLM Agent implementation to meet specific project requirements?\n",
      "4. **Integration with Existing Tools**: Will the platform integrate seamlessly with existing development tools and frameworks, or will users need to adapt their workflows to accommodate the new platform?\n",
      "5. **Ethics and Bias**: How will the platform address potential biases in the LLM Agents' decision-making processes, particularly in areas like fairness, transparency, and accountability?\n",
      "\n",
      "To further develop this project idea, consider gathering feedback from potential users, industry experts, and developers to refine the platform's features and capabilities. Additionally, research existing software development platforms and tools to understand their strengths and weaknesses, and identify opportunities for innovation and differentiation.\n",
      "\n",
      "Overall, the AI Software Factory project has the potential to revolutionize the way we develop software, making it more efficient, scalable, and accessible to a wider audience. With careful planning, execution, and ongoing iteration, this platform can become a leading player in the software development landscape.\n"
     ]
    }
   ],
   "source": [
    "project_idea_feedback = model.invoke(filled_prompt)\n",
    "print(project_idea_feedback)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Implement Refinement Loop\n",
    "\n",
    "We will implement a refinement loop to allow the user to provide additional input and receive updated feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the user's additional input, I've refined the project description:\n",
      "\n",
      "**Project Title:** AI-Driven Software Factory with Human Review Gates\n",
      "\n",
      "**Project Description:**\n",
      "\n",
      "The goal of this innovative software development project is to create an AI-powered factory that generates high-quality software solutions from project ideas. The system will utilize a combination of LLM (Large Language Model) Agents and human reviewers as \"gates\" between project steps, ensuring the integrity and quality of the generated software.\n",
      "\n",
      "**Key Components:**\n",
      "\n",
      "1. **Project Idea Input**: Users will input their project ideas into the AI factory, which will be analyzed and used to generate a customized software development plan.\n",
      "2. **LLM Agent Workflows**: The LLM Agents will follow a step-by-step software process, generating code, designs, and documentation based on the project idea. This workflow will include tasks such as:\n",
      "\t* Requirements gathering\n",
      "\t* Designing user interfaces and architectures\n",
      "\t* Implementing algorithms and data structures\n",
      "\t* Testing and debugging\n",
      "3. **Human Review Gates**: At each step of the software development process, human reviewers will be integrated as \"gates\" to assess the quality and validity of the generated code, designs, and documentation. These gate reviews will ensure that the output meets the required standards and is free from errors.\n",
      "4. **AI-Driven Iteration**: Based on the feedback from human reviewers, the LLM Agents will refine and iterate on the generated software, making adjustments as needed to meet the project requirements.\n",
      "5. **Continuous Learning**: The AI factory will learn from the feedback received during the review process, incorporating this knowledge into future iterations and improving the overall quality of the generated software.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* Fast and efficient software development\n",
      "* High-quality software solutions with minimal human intervention\n",
      "* Continuous learning and improvement through AI-driven iteration\n",
      "* Integration of human expertise to ensure quality and validity\n",
      "\n",
      "**Target Audience:**\n",
      "\n",
      "* Software developers who want to leverage AI for faster and more accurate development\n",
      "* Businesses seeking to accelerate their software development timelines\n",
      "* Individuals looking to create custom software solutions without extensive coding knowledge\n",
      "\n",
      "By combining the strengths of LLM Agents with human review gates, this project aims to revolutionize the software development process, enabling rapid creation of high-quality software solutions while maintaining the highest standards of quality and accuracy.\n",
      "Here is an updated project description:\n",
      "\n",
      "**Project Title:** AI-Driven Software Factory - \"LLM-Agentized\" Project Generation\n",
      "\n",
      "**Objective:**\n",
      "\n",
      "Create a software factory that utilizes Large Language Model (LLM) Agents to generate software from project ideas. The goal is to automate the software development process, enabling users to provide high-level input and receive fully functional software solutions.\n",
      "\n",
      "**Project Description:**\n",
      "\n",
      "The AI-Driven Software Factory will employ LLM Agents to guide users through a step-by-step process of generating software from project ideas. This process will include:\n",
      "\n",
      "1. **Project Idea Input**: Users will provide an initial project idea, which will undergo a series of iteration steps to clarify and refine the concept. These steps may include:\n",
      "\t* Brainstorming: Identify key features, functionalities, and technical requirements.\n",
      "\t* Requirements Gathering: Clarify user needs and specifications.\n",
      "\t* Problem Definition: Define the problem statement or opportunity for software development.\n",
      "2. **LLM Agent Implementation**: The refined project idea will be used to create a set of instructions that the LLM Agent can understand. These instructions will outline the desired software architecture, design patterns, and technical requirements.\n",
      "3. **Software Generation**: The LLM Agent will execute the instructions, generating software code based on the provided project idea and specifications.\n",
      "4. **Review and Refinement**: A human reviewer will assess the generated software to ensure it meets the user's expectations. Any necessary revisions will be performed, ensuring the final product meets the required standards.\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* User-friendly interface for providing project ideas and iterating feedback\n",
      "* Iterative process to refine project concepts and improve clarity\n",
      "* LLM Agent implementation to automate software generation\n",
      "* Human review and refinement to ensure high-quality output\n",
      "\n",
      "By utilizing this AI-driven approach, the software factory aims to increase developer productivity, reduce costs, and enhance overall software development efficiency.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    additional_input = input(\"Please provide additional input to refine your project idea (or type 'exit' to finish): \")\n",
    "    if not additional_input.strip():\n",
    "        break\n",
    "\n",
    "    refinement_prompt_template = \"\"\"\n",
    "    You are an AI assistant. The user has provided a project description and additional input to refine the project idea.\n",
    "    Provide an updated project description that addresses the user's input.\n",
    "\n",
    "    {project_idea}\n",
    "\n",
    "    Additional Input: {additional_input}\n",
    "    \"\"\"\n",
    "    \n",
    "    refinement_prompt = refinement_prompt_template.format(project_idea=project_idea, additional_input=additional_input)\n",
    "    updated_feedback_summary_plan = model.invoke(refinement_prompt)\n",
    "    print(updated_feedback_summary_plan)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
