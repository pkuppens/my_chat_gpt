{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_Website_Scraping_Playwright\n",
    "\n",
    "This notebook demonstrates how to scrape dynamic website content using Playwright and handle authentication for LinkedIn and Medium. We will cover the installation of necessary packages, configuration, and connection to the websites, as well as converting the scraped content into vector embeddings using LangChain and summarizing the content from memory in markdown format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Necessary Packages\n",
    "\n",
    "First, we need to install the required packages. Run the following command to install Playwright, LangChain, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q playwright langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Packages\n",
    "\n",
    "Next, we will import the necessary packages for our setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.sync_api import sync_playwright\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Playwright and Handle Authentication\n",
    "\n",
    "We need to configure Playwright to handle authentication for LinkedIn and Medium. The following code sets up the connection and handles the login process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_linkedin(page, username, password):\n",
    "    page.goto('https://www.linkedin.com/login')\n",
    "    page.fill('input[name=\"session_key\"]', username)\n",
    "    page.fill('input[name=\"session_password\"]', password)\n",
    "    page.click('button[type=\"submit\"]')\n",
    "\n",
    "def login_medium(page, username, password):\n",
    "    page.goto('https://medium.com/m/signin')\n",
    "    page.fill('input[name=\"email\"]', username)\n",
    "    page.click('button[type=\"submit\"]')\n",
    "    # Medium sends a login link to the email, so manual intervention is needed here\n",
    "    print(\"Please check your email and click the login link sent by Medium.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Scrape Dynamic Website Content\n",
    "\n",
    "We will use Playwright to scrape dynamic website content from LinkedIn and Medium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_profile(page, profile_url):\n",
    "    page.goto(profile_url)\n",
    "    content = page.content()\n",
    "    return content\n",
    "\n",
    "def scrape_medium_article(page, article_url):\n",
    "    page.goto(article_url)\n",
    "    content = page.content()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Convert Scraped Content into Vector Embeddings\n",
    "\n",
    "We will use LangChain to convert the scraped content into vector embeddings and store them in a Chroma vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_embeddings(content):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_text(content)\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vector_store = Chroma.from_texts(texts, embeddings)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Summarize Content from Memory\n",
    "\n",
    "We will use LangChain to summarize the content from memory in markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_content(vector_store):\n",
    "    llm = OpenAI()\n",
    "    chain = LLMChain(llm=llm)\n",
    "    summary = chain.run(vector_store)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Interactive Demonstration\n",
    "\n",
    "We will demonstrate the entire process interactively, with clear markdown cells explaining each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sync_playwright() as p:\n",
    "    browser = p.chromium.launch(headless=False)\n",
    "    page = browser.new_page()\n",
    "\n",
    "    # LinkedIn login\n",
    "    linkedin_username = os.getenv('LINKEDIN_USERNAME')\n",
    "    linkedin_password = os.getenv('LINKEDIN_PASSWORD')\n",
    "    login_linkedin(page, linkedin_username, linkedin_password)\n",
    "\n",
    "    # Scrape LinkedIn profile\n",
    "    linkedin_profile_url = 'https://www.linkedin.com/in/some-profile/'\n",
    "    linkedin_content = scrape_linkedin_profile(page, linkedin_profile_url)\n",
    "\n",
    "    # Convert LinkedIn content to embeddings\n",
    "    linkedin_vector_store = convert_to_embeddings(linkedin_content)\n",
    "\n",
    "    # Summarize LinkedIn content\n",
    "    linkedin_summary = summarize_content(linkedin_vector_store)\n",
    "    print(\"LinkedIn Summary:\", linkedin_summary)\n",
    "\n",
    "    # Medium login\n",
    "    medium_username = os.getenv('MEDIUM_USERNAME')\n",
    "    medium_password = os.getenv('MEDIUM_PASSWORD')\n",
    "    login_medium(page, medium_username, medium_password)\n",
    "\n",
    "    # Scrape Medium article\n",
    "    medium_article_url = 'https://medium.com/some-article'\n",
    "    medium_content = scrape_medium_article(page, medium_article_url)\n",
    "\n",
    "    # Convert Medium content to embeddings\n",
    "    medium_vector_store = convert_to_embeddings(medium_content)\n",
    "\n",
    "    # Summarize Medium content\n",
    "    medium_summary = summarize_content(medium_vector_store)\n",
    "    print(\"Medium Summary:\", medium_summary)\n",
    "\n",
    "    browser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
